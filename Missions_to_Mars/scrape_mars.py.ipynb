{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def browserexec():\n",
    "    executable_path = {\"executable_path\": \"/usr/local/bin/chromedriver\"}\n",
    "    return Browser(\"chrome\", **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape():\n",
    "    browser = browserexec()\n",
    "\n",
    "    # Scrape latest title and paragraph\n",
    "    \n",
    "    browser.visit('https://redplanetscience.com/')\n",
    "    html = browser.html\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "\n",
    "    ### Get first news title and paragraph\n",
    "    quote = soup.find('div', class_='content_title').text\n",
    "    summary = soup.find('div', class_='article_teaser_body').text\n",
    "\n",
    "    \n",
    "    # Scrape for feautured image\n",
    "    \n",
    "    browser.visit('https://spaceimages-mars.com/')\n",
    "    html_img = browser.html\n",
    "    soup_img = BeautifulSoup(html_img, 'html.parser')\n",
    "\n",
    "    ### Get image source\n",
    "    img_link = soup_img.find('img', class_='headerimage fade-in')\n",
    "    img_link = img_link['src']\n",
    "\n",
    "    ### Get link of image source\n",
    "    featured_img_link = str(url_img) + str(img_link)\n",
    "\n",
    "\n",
    "    # Scrape for Mars Facts\n",
    "    \n",
    "    browser.visit('https://galaxyfacts-mars.com')\n",
    "    \n",
    "    ### Read table and print\n",
    "    df_list = pd.read_html('https://galaxyfacts-mars.com')\n",
    "    table = df_list[1].head(7)\n",
    "    table = table.rename(columns={0: \"Fact\", 1: \"Value\"})\n",
    "    \n",
    "    ### table to html\n",
    "    html_table = table.to_html()\n",
    "    \n",
    "\n",
    "\n",
    "    # MARS Hemispheres\n",
    "    html_hem = browser.html\n",
    "    soup_hem = BeautifulSoup(html_hem, 'html.parser')\n",
    "\n",
    "    #finding section that contains information about each hemisphere\n",
    "    hem_data = soup_hem.find_all('div', class_=\"collapsible results\")\n",
    "    names = hem_data[0].find_all('h3')\n",
    "\n",
    "    name_list = []\n",
    "\n",
    "    # Loop through each name\n",
    "    for name in names: \n",
    "        name_list.append(name.text)\n",
    "\n",
    "    # loop through each image link\n",
    "\n",
    "    links = hem_data[0].find_all('a')\n",
    "    links_dict = []\n",
    "\n",
    "    for link in links:\n",
    "        if (link.img):\n",
    "            url_img = url_hem + link['href']\n",
    "            links_dict.append(url_img)\n",
    "\n",
    "    # from each of the links, grab the photo\n",
    "\n",
    "    images = []\n",
    "\n",
    "    for url in links_dict:\n",
    "\n",
    "        browser.visit(url)\n",
    "        html = browser.html\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "        # find image and append\n",
    "        image = soup.find_all('img', class_='wide-image')\n",
    "        image_src = image[0]['src']\n",
    "        good_img_link = url_hem + image_src\n",
    "        images.append(good_img_link)\n",
    "    \n",
    "    #create dataframe to add titles\n",
    "    title_creator = pd.DataFrame({'Name':name_list,\"Img_Link\":images})\n",
    "    # transfer df to dictionary\n",
    "    dictionary = title_creator.to_dict()\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    # All data\n",
    "    all_data = {\n",
    "        \"Title\": quote,\n",
    "        \"Paragraph\": summary,\n",
    "        \"Featured_image\": featured_img_link,\n",
    "        \"Facts\": table,\n",
    "        \"hemispheres\": dictionary\n",
    "    }\n",
    "\n",
    "    # Close the browser after scraping\n",
    "    browser.quit()\n",
    "\n",
    "    # Return results\n",
    "    return all_data\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
